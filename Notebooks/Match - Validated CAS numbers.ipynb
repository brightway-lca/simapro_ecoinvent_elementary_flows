{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d671a1da-94b0-4732-83d1-ffdc1801b110",
   "metadata": {},
   "source": [
    "# Match missing by validated CAS numbers\n",
    "\n",
    "Validate and then use CAS numbers for matching where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97dd6915-0af6-4563-8284-ad7b07d26036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "from numbers import Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aff657d-cb27-4dde-aea7-e3d907a6f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_data_dir = (Path.cwd().parent / \"Mapping\" / \"Output\" / \"Unmatched\").resolve()\n",
    "output_dir = (Path.cwd().parent / \"Contribute\").resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f057e2-4cc1-4ad1-8a97-eb6a523b0d1e",
   "metadata": {},
   "source": [
    "Read input dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df061563-9872-4d69-93de-b7aac700c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_csv(unmatched_data_dir / 'SimaProv9.4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b61570-d3dc-4549-9814-02002d94171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ei = pd.read_csv(unmatched_data_dir / 'ecoinventEFv3.7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e92f8-fb38-4e58-a931-7b25ff2c3006",
   "metadata": {},
   "source": [
    "## Validating CAS numbers\n",
    "\n",
    "Just because we have them doesn't make them correct.\n",
    "\n",
    "Based on code from [happy_family](https://github.com/Depart-de-Sentier/happy_family/blob/main/Elementary%20flow%20lists/Generate%20elementary%20flow%20lists.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b6e7cea-1fab-4fa9-8374-f5bafc18d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_cas(s):\n",
    "    ERROR = \"CAS Check Digit error: CAS '{}' has check digit of {}, but it should be {}\"\n",
    "    \n",
    "    if isinstance(s, str):\n",
    "        s = s.strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    elif isinstance(s, Number) and np.isnan(s):\n",
    "        return None\n",
    "    \n",
    "    total = sum((a + 1) * int(b) for a, b in zip(range(9), s.replace(\"-\", \"\")[-2::-1]))\n",
    "    if not total % 10 == int(s[-1]):\n",
    "        print(\"CAS not valid: {} ({})\".format(s, ERROR.format(s, s[-1], total % 10)))\n",
    "        return None\n",
    "    return s\n",
    "                \n",
    "\n",
    "def check_cas(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    assert s.count(\"-\") == 2\n",
    "    check_digit(s)\n",
    "    return True\n",
    "\n",
    "\n",
    "def zero_pad_cas(s):\n",
    "    if not s:\n",
    "        return s\n",
    "    zeros = \"0\" * (12- len(s))\n",
    "    return zeros + s\n",
    "    \n",
    "    \n",
    "def no_padding_cas(s):\n",
    "    if not s:\n",
    "        return s\n",
    "    return s.lstrip(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "040814f3-15a7-4ab7-9afe-004f8c624f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ei[\"Valid CAS\"] = ei[\"CASNo\"].apply(validate_cas)\n",
    "ei = ei[ei[\"Valid CAS\"] != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6942b1f7-390a-4139-bc8c-17e65c7352e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp[\"Valid CAS\"] = sp[\"CAS No\"].apply(validate_cas)\n",
    "sp = sp[sp[\"Valid CAS\"] != None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b47b3-253e-438d-be3a-0870258f6860",
   "metadata": {},
   "source": [
    "Example of how to combine dataframes using [merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html). We already have these matches, this is only an example :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4679c1b8-cd17-46c5-ad20-6b037f900d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140547"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sp.merge(ei, how=\"inner\", on=[\"Valid CAS\", \"Context\"])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d3273-0ba6-4e44-bdd7-3cc52b1377ac",
   "metadata": {},
   "source": [
    "Adjust columns to match expected format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ccb41-da4e-4e5d-a678-7cca5faa8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_names_after_merge(df):\n",
    "    mapping = {\n",
    "        'Flow UUID': 'SourceFlowUUID', \n",
    "        'FlowUUID': 'TargetFlowUUID',  # Incorrect column header in provided ecoinvent data\n",
    "        'Flowable_x': 'SourceFlowName', \n",
    "        'Flowable_y': 'TargetFlowName',\n",
    "        'Unit_x': 'SourceUnit',\n",
    "        'Unit_y': 'TargetUnit',\n",
    "        'Context_x': 'SourceFlowContext',\n",
    "        'Context_y': 'TargetFlowContext',\n",
    "    }\n",
    "    return df.rename(columns={k: v for k, v in mapping.items() if k in df.columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f417efd-2258-4608-9ccc-ad9d6cba69e4",
   "metadata": {},
   "source": [
    "Add some useful columns.\n",
    "\n",
    "* `author` is your name\n",
    "* `notebook_name` is the name of this notebook; we can't figure this out automatically. It should normally start with `Match -`.\n",
    "* `default_match_condition` is one of `=`, `~`, `<`, or `>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53603a21-53d7-4c6c-94bd-73bd52cb96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_common_columns(df, author, notebook_name, default_match_condition=\"=\"):\n",
    "    df['SourceListName'] = 'SimaPro9.4'\n",
    "    df['TargetListName'] = 'ecoinventEFv3.7'\n",
    "    df['MatchCondition'] = default_match_condition\n",
    "    df['Mapper'] = author\n",
    "    df['MemoMapper'] = f'Automated match. Notebook: {notebook_name}'\n",
    "    df['MemoSource'] = ''\n",
    "    df['MemoTarget'] = ''\n",
    "    df['MemoVerifier'] = ''\n",
    "    df['LastUpdated'] = datetime.now(timezone.utc).astimezone().isoformat()\n",
    "    df['Verifier'] = ''\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdaa414-7582-4be3-966d-cb4cc5692107",
   "metadata": {},
   "source": [
    "Make sure the required columns are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a8f45-666a-4c86-82c2-e5e9a9c00d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_required_columns(df):\n",
    "    expected = set([     \n",
    "        \"SourceListName\", \"SourceFlowName\", \"SourceFlowUUID\", \"SourceFlowContext\", \"SourceUnit\", \n",
    "        \"MatchCondition\", \"TargetListName\", \"TargetFlowName\", \"TargetFlowUUID\", \n",
    "        \"TargetFlowContext\", \"TargetUnit\", \"Mapper\", \"Verifier\", \"LastUpdated\", \"MemoMapper\", \n",
    "        \"MemoVerifier\", \"MemoSource\", \"MemoTarget\"\n",
    "    ])\n",
    "    given = set(df.columns)\n",
    "    difference = expected.difference(given)\n",
    "    if difference:\n",
    "        print(\"Missing the following required columns:\", difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38805d39-e02e-4738-83ac-ea319a7914a3",
   "metadata": {},
   "source": [
    "Export the dataframe to the `contribute` directory. Please make your filename meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf16e12-6c54-4013-826e-cba7d7c1dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_dataframe(df, name):\n",
    "    SPEC_COLUMNS = [\n",
    "        \"SourceListName\", \"SourceFlowName\", \"SourceFlowUUID\", \"SourceFlowContext\", \"SourceUnit\", \n",
    "        \"MatchCondition\", \"ConversionFactor\", \"TargetListName\", \"TargetFlowName\", \"TargetFlowUUID\", \n",
    "        \"TargetFlowContext\", \"TargetUnit\", \"Mapper\", \"Verifier\", \"LastUpdated\", \"MemoMapper\", \n",
    "        \"MemoVerifier\", \"MemoSource\", \"MemoTarget\"\n",
    "    ]\n",
    "    \n",
    "    df = df[[col for col in SPEC_COLUMNS if col in df.columns]]\n",
    "    \n",
    "    if not name.lower().endswith(\".csv\"):\n",
    "        name += \".csv\"\n",
    "    \n",
    "    df.to_csv(output_dir / name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
